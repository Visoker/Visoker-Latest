import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.datasets import boston_housing
import pandas as pd
from sklearn.compose import make_column_transformer
from sklearn.preprocessing import MinMaxScaler

# Load the Boston Housing dataset
(X_train, y_train), (X_test, y_test) = boston_housing.load_data()


ct = make_column_transformer((MinMaxScaler(),[0,1,2,3,4,5,6,7,8,9,10,11,12]))

# Perform feature scaling
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)


# Build the deep neural network model
model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(1)
])


# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')


# Train the model
history = model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=1)


# Evaluate the model on the testing set
loss = model.evaluate(X_test, y_test, verbose=0)
print('Mean Squared Error (MSE) on test data:', loss)


# Make predictions on the X_test dataset
predictions = model.predict(X_test)


predictions[1] , y_test[1]


# Display the predicted prices
for i in range(len(predictions)):
    print(f"Predicted price: {predictions[i][0]:.2f}, Actual price: {y_test[i]}")
